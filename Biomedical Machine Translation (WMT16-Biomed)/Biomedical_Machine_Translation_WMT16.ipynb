{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10111384,
          "sourceType": "datasetVersion",
          "datasetId": 6238034
        },
        {
          "sourceId": 10114702,
          "sourceType": "datasetVersion",
          "datasetId": 6240495
        }
      ],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Biomedical Machine Translation on the WMT16-Biomedical Dataset\n",
        "\n",
        "Dataset taken from: https://www.statmt.org/wmt16/biomedical-translation-task.html\n",
        "\n",
        "The following experiments explore mBart (facebook/mbart-large-50-many-to-many-mmt), OPUS-MT (Helsinki-NLP/opus-mt-es-en), and T5 (google-t5/t5-small) models for Machine Translation."
      ],
      "metadata": {
        "id": "qLTe9-LcBXUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing libraries and setup"
      ],
      "metadata": {
        "id": "CAyRtmRiCTWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install needed libraries\n",
        "! pip install transformers datasets sacrebleu evaluate"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T01:59:16.883421Z",
          "iopub.execute_input": "2024-12-06T01:59:16.883901Z",
          "iopub.status.idle": "2024-12-06T01:59:27.23852Z",
          "shell.execute_reply.started": "2024-12-06T01:59:16.883872Z",
          "shell.execute_reply": "2024-12-06T01:59:27.237698Z"
        },
        "id": "5uReRQWz-dJa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorForSeq2Seq, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T01:59:27.24019Z",
          "iopub.execute_input": "2024-12-06T01:59:27.240487Z",
          "iopub.status.idle": "2024-12-06T01:59:46.25807Z",
          "shell.execute_reply.started": "2024-12-06T01:59:27.24046Z",
          "shell.execute_reply": "2024-12-06T01:59:46.257389Z"
        },
        "id": "-bMpWr76-dJa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/kaggle/input/wmt16-biomed-en-es/wmt16_biomedical_data_en_es.csv\"\n",
        "dataset = load_dataset(\"csv\", data_files=data_dir)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T01:59:46.259164Z",
          "iopub.execute_input": "2024-12-06T01:59:46.259867Z",
          "iopub.status.idle": "2024-12-06T01:59:48.068857Z",
          "shell.execute_reply.started": "2024-12-06T01:59:46.259828Z",
          "shell.execute_reply": "2024-12-06T01:59:48.068013Z"
        },
        "id": "EogG19O9-dJb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# split into test, train, val\n",
        "# 80% train, 20% test + validation\n",
        "temp = dataset[\"train\"].train_test_split(test_size=0.2)\n",
        "\n",
        "# Split the 20% test + valid in half test, half valid\n",
        "temp2 = temp[\"test\"].train_test_split(test_size=0.5)\n",
        "\n",
        "dataset = DatasetDict({\n",
        "\"train\": temp[\"train\"],\n",
        "\"test\": temp2[\"test\"],\n",
        "\"val\": temp2[\"train\"]})\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:00:39.810116Z",
          "iopub.execute_input": "2024-12-06T02:00:39.810749Z",
          "iopub.status.idle": "2024-12-06T02:00:39.900657Z",
          "shell.execute_reply.started": "2024-12-06T02:00:39.810713Z",
          "shell.execute_reply": "2024-12-06T02:00:39.899757Z"
        },
        "id": "LVi2c-5R-dJb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    MBartForConditionalGeneration, MBartTokenizer,\n",
        "    Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "  )\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import random_split\n",
        "import datasets\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "import datasets"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:00:40.375299Z",
          "iopub.execute_input": "2024-12-06T02:00:40.376003Z",
          "iopub.status.idle": "2024-12-06T02:00:46.951657Z",
          "shell.execute_reply.started": "2024-12-06T02:00:40.375969Z",
          "shell.execute_reply": "2024-12-06T02:00:46.950833Z"
        },
        "id": "mqxMQUQN-dJb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint=\"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:00:46.953223Z",
          "iopub.execute_input": "2024-12-06T02:00:46.953534Z",
          "iopub.status.idle": "2024-12-06T02:00:49.82115Z",
          "shell.execute_reply.started": "2024-12-06T02:00:46.953483Z",
          "shell.execute_reply": "2024-12-06T02:00:49.820424Z"
        },
        "id": "ZyQahUqe-dJc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = MBartForConditionalGeneration.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:00:49.8221Z",
          "iopub.execute_input": "2024-12-06T02:00:49.822376Z",
          "iopub.status.idle": "2024-12-06T02:00:56.198558Z",
          "shell.execute_reply.started": "2024-12-06T02:00:49.82235Z",
          "shell.execute_reply": "2024-12-06T02:00:56.197546Z"
        },
        "id": "_HBzhJ00-dJc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-Processing"
      ],
      "metadata": {
        "id": "lcZp3CHiBS0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = 128\n",
        "max_target_length = 128\n",
        "\n",
        "source_lang = \"es\"\n",
        "target_lang = \"en\"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [example for example in examples[\"es\"]]\n",
        "    targets = [example for example in examples[\"en\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "\n",
        "    # Setup the tokenizer for targets\n",
        "    labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:00:56.201025Z",
          "iopub.execute_input": "2024-12-06T02:00:56.201365Z",
          "iopub.status.idle": "2024-12-06T02:00:56.208513Z",
          "shell.execute_reply.started": "2024-12-06T02:00:56.201328Z",
          "shell.execute_reply": "2024-12-06T02:00:56.207575Z"
        },
        "id": "QJ1nxXaQ-dJc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:00:56.209682Z",
          "iopub.execute_input": "2024-12-06T02:00:56.210063Z",
          "iopub.status.idle": "2024-12-06T02:01:19.002136Z",
          "shell.execute_reply.started": "2024-12-06T02:00:56.210027Z",
          "shell.execute_reply": "2024-12-06T02:01:19.001231Z"
        },
        "id": "LBcchdpT-dJc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:01:19.003493Z",
          "iopub.execute_input": "2024-12-06T02:01:19.00395Z",
          "iopub.status.idle": "2024-12-06T02:01:19.008869Z",
          "shell.execute_reply.started": "2024-12-06T02:01:19.003907Z",
          "shell.execute_reply": "2024-12-06T02:01:19.007944Z"
        },
        "id": "OYl_fPXj-dJc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:01:19.009912Z",
          "iopub.execute_input": "2024-12-06T02:01:19.010147Z",
          "iopub.status.idle": "2024-12-06T02:01:19.842327Z",
          "shell.execute_reply.started": "2024-12-06T02:01:19.010124Z",
          "shell.execute_reply": "2024-12-06T02:01:19.841701Z"
        },
        "id": "5K0mNjK8-dJc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:01:19.84331Z",
          "iopub.execute_input": "2024-12-06T02:01:19.843959Z",
          "iopub.status.idle": "2024-12-06T02:01:19.850617Z",
          "shell.execute_reply.started": "2024-12-06T02:01:19.843929Z",
          "shell.execute_reply": "2024-12-06T02:01:19.849714Z"
        },
        "id": "BXQrabOw-dJc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# mBart50"
      ],
      "metadata": {
        "id": "4wGH_BMh-dJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mBart Training"
      ],
      "metadata": {
        "id": "iWQymPk5BO0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "accelerator = Accelerator()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:01:19.851823Z",
          "iopub.execute_input": "2024-12-06T02:01:19.852134Z",
          "iopub.status.idle": "2024-12-06T02:01:19.939486Z",
          "shell.execute_reply.started": "2024-12-06T02:01:19.852107Z",
          "shell.execute_reply": "2024-12-06T02:01:19.93834Z"
        },
        "id": "A0_k9mZw-dJc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "args = Seq2SeqTrainingArguments(output_dir=\"mbart_large_50_mmt_biomed_es_en_v1\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=0.1,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"/logs\",\n",
        "    logging_steps=10000,\n",
        "    save_steps=10000,\n",
        "    report_to=\"none\",\n",
        "    push_to_hub=False\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(model=model,\n",
        "    args=args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"val\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "tokenized_dataset, trainer = accelerator.prepare(\n",
        "    tokenized_dataset, trainer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:02:17.215222Z",
          "iopub.execute_input": "2024-12-06T02:02:17.215963Z",
          "iopub.status.idle": "2024-12-06T02:15:12.3557Z",
          "shell.execute_reply.started": "2024-12-06T02:02:17.215926Z",
          "shell.execute_reply": "2024-12-06T02:15:12.354839Z"
        },
        "id": "-CtdPY3c-dJd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mBart Evaluation"
      ],
      "metadata": {
        "id": "A1KHZthuBBIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model checkpoint\n",
        "model = MBartForConditionalGeneration.from_pretrained(\"/kaggle/working/mbart_large_50_mmt_biomed_es_en_v1/checkpoint-288\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T01:39:12.411846Z",
          "iopub.execute_input": "2024-12-06T01:39:12.412934Z",
          "iopub.status.idle": "2024-12-06T01:39:17.169119Z",
          "shell.execute_reply.started": "2024-12-06T01:39:12.412892Z",
          "shell.execute_reply": "2024-12-06T01:39:17.167774Z"
        },
        "id": "Ne-e7Thi-dJd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "args = Seq2SeqTrainingArguments(output_dir=\"mbart_large_50_mmt_biomed_es_en_v1\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=0.01,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"/logs\",\n",
        "    logging_steps=10000,\n",
        "    save_steps=10000,\n",
        "    report_to=\"none\",\n",
        "    push_to_hub=False\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(model=model,\n",
        "    args=args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"val\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "tokenized_dataset, trainer = accelerator.prepare(\n",
        "    tokenized_dataset, trainer\n",
        ")\n",
        "\n",
        "trainer.evaluate()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T01:40:01.99979Z",
          "iopub.execute_input": "2024-12-06T01:40:02.000501Z",
          "iopub.status.idle": "2024-12-06T01:40:36.860012Z",
          "shell.execute_reply.started": "2024-12-06T01:40:02.000464Z",
          "shell.execute_reply": "2024-12-06T01:40:36.859222Z"
        },
        "id": "lVT8TmLN-dJd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(tokenized_dataset[\"val\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T01:41:45.602865Z",
          "iopub.execute_input": "2024-12-06T01:41:45.6032Z",
          "iopub.status.idle": "2024-12-06T01:42:20.341399Z",
          "shell.execute_reply.started": "2024-12-06T01:41:45.603169Z",
          "shell.execute_reply": "2024-12-06T01:42:20.340584Z"
        },
        "id": "kg6SLV2z-dJd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.metrics"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T02:51:32.76954Z",
          "iopub.execute_input": "2024-12-06T02:51:32.77035Z",
          "iopub.status.idle": "2024-12-06T02:51:32.776801Z",
          "shell.execute_reply.started": "2024-12-06T02:51:32.770299Z",
          "shell.execute_reply": "2024-12-06T02:51:32.775781Z"
        },
        "id": "2-w21fum-dJe",
        "outputId": "09faa67e-1568-4a97-d5cc-a7458188f287"
      },
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'test_loss': 0.7604455947875977,\n 'test_bleu': 48.1032,\n 'test_gen_len': 21.1874,\n 'test_runtime': 1331.2933,\n 'test_samples_per_second': 8.648,\n 'test_steps_per_second': 1.082}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OPUS MT"
      ],
      "metadata": {
        "id": "yyY69g88-dJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T18:26:58.506031Z",
          "iopub.execute_input": "2024-12-05T18:26:58.506949Z",
          "iopub.status.idle": "2024-12-05T18:27:03.860715Z",
          "shell.execute_reply.started": "2024-12-05T18:26:58.506906Z",
          "shell.execute_reply": "2024-12-05T18:27:03.859856Z"
        },
        "id": "9fvg58tn-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/kaggle/input/wmt16-biomedical-mt-en-es/wmt16_biomedical_data_en_es.csv\"\n",
        "dataset = load_dataset(\"csv\", data_files=data_dir)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T19:59:02.953565Z",
          "iopub.execute_input": "2024-12-05T19:59:02.954455Z",
          "iopub.status.idle": "2024-12-05T19:59:03.185275Z",
          "shell.execute_reply.started": "2024-12-05T19:59:02.954404Z",
          "shell.execute_reply": "2024-12-05T19:59:03.184435Z"
        },
        "id": "y42cB53z-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "\n",
        "# split into test, train, val\n",
        "# 80% train, 20% test + validation\n",
        "temp = dataset[\"train\"].train_test_split(test_size=0.2)\n",
        "\n",
        "# Split the 20% test + valid in half test, half valid\n",
        "temp2 = temp[\"test\"].train_test_split(test_size=0.5)\n",
        "\n",
        "dataset = DatasetDict({\n",
        "\"train\": temp[\"train\"],\n",
        "\"test\": temp2[\"test\"],\n",
        "\"val\": temp2[\"train\"]})\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T19:59:05.070698Z",
          "iopub.execute_input": "2024-12-05T19:59:05.071036Z",
          "iopub.status.idle": "2024-12-05T19:59:05.157534Z",
          "shell.execute_reply.started": "2024-12-05T19:59:05.071004Z",
          "shell.execute_reply": "2024-12-05T19:59:05.156684Z"
        },
        "id": "uywWP578-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T19:59:09.764866Z",
          "iopub.execute_input": "2024-12-05T19:59:09.765214Z",
          "iopub.status.idle": "2024-12-05T19:59:09.77085Z",
          "shell.execute_reply.started": "2024-12-05T19:59:09.765182Z",
          "shell.execute_reply": "2024-12-05T19:59:09.769863Z"
        },
        "id": "_vCTOxMr-dJm",
        "outputId": "19d231cb-28fe-4a42-d963-522265358469"
      },
      "outputs": [
        {
          "execution_count": 105,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'train': (230248, 3), 'test': (28782, 3), 'val': (28781, 3)}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "source_lang = \"es\"\n",
        "target_lang = \"en\"\n",
        "prefix = \"\"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + example for example in examples[\"es\"]]\n",
        "    targets = [example for example in examples[\"en\"]]\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=256, truncation=True)\n",
        "    return model_inputs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T19:59:12.755057Z",
          "iopub.execute_input": "2024-12-05T19:59:12.755879Z",
          "iopub.status.idle": "2024-12-05T19:59:12.760468Z",
          "shell.execute_reply.started": "2024-12-05T19:59:12.75584Z",
          "shell.execute_reply": "2024-12-05T19:59:12.759617Z"
        },
        "id": "rj2XmhzK-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T19:59:13.386149Z",
          "iopub.execute_input": "2024-12-05T19:59:13.387147Z",
          "iopub.status.idle": "2024-12-05T20:00:06.573986Z",
          "shell.execute_reply.started": "2024-12-05T19:59:13.387113Z",
          "shell.execute_reply": "2024-12-05T20:00:06.572904Z"
        },
        "id": "a-rbWMXp-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"Helsinki-NLP/opus-mt-es-en\"\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T20:00:06.575741Z",
          "iopub.execute_input": "2024-12-05T20:00:06.576051Z",
          "iopub.status.idle": "2024-12-05T20:00:06.580811Z",
          "shell.execute_reply.started": "2024-12-05T20:00:06.576023Z",
          "shell.execute_reply": "2024-12-05T20:00:06.57958Z"
        },
        "id": "aplRrmtB-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T20:00:06.581743Z",
          "iopub.execute_input": "2024-12-05T20:00:06.581968Z",
          "iopub.status.idle": "2024-12-05T20:00:07.149719Z",
          "shell.execute_reply.started": "2024-12-05T20:00:06.581943Z",
          "shell.execute_reply": "2024-12-05T20:00:07.149051Z"
        },
        "id": "PbHhc3mz-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T20:00:07.151596Z",
          "iopub.execute_input": "2024-12-05T20:00:07.151867Z",
          "iopub.status.idle": "2024-12-05T20:00:07.156586Z",
          "shell.execute_reply.started": "2024-12-05T20:00:07.151841Z",
          "shell.execute_reply": "2024-12-05T20:00:07.155658Z"
        },
        "id": "0bTsx1fr-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:47:28.894721Z",
          "iopub.execute_input": "2024-12-05T21:47:28.895438Z",
          "iopub.status.idle": "2024-12-05T21:47:28.901558Z",
          "shell.execute_reply.started": "2024-12-05T21:47:28.895376Z",
          "shell.execute_reply": "2024-12-05T21:47:28.900668Z"
        },
        "id": "YElgIZnC-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPUS-MT Training"
      ],
      "metadata": {
        "id": "or1d1Mfl-dJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:47:53.655485Z",
          "iopub.execute_input": "2024-12-05T21:47:53.655828Z",
          "iopub.status.idle": "2024-12-05T21:47:55.136175Z",
          "shell.execute_reply.started": "2024-12-05T21:47:53.655796Z",
          "shell.execute_reply": "2024-12-05T21:47:55.135446Z"
        },
        "id": "4BuyGLY3-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating before training"
      ],
      "metadata": {
        "id": "IWWqeaXB-dJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation\", model=checkpoint, device=\"cuda\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:47:55.769712Z",
          "iopub.execute_input": "2024-12-05T21:47:55.770308Z",
          "iopub.status.idle": "2024-12-05T21:47:57.409671Z",
          "shell.execute_reply.started": "2024-12-05T21:47:55.770275Z",
          "shell.execute_reply": "2024-12-05T21:47:57.408957Z"
        },
        "id": "MCf03lrT-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = translator([example['es'] for example in dataset[\"test\"]][:5])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:47:58.756256Z",
          "iopub.execute_input": "2024-12-05T21:47:58.756918Z",
          "iopub.status.idle": "2024-12-05T21:48:01.325049Z",
          "shell.execute_reply.started": "2024-12-05T21:47:58.756879Z",
          "shell.execute_reply": "2024-12-05T21:48:01.324128Z"
        },
        "id": "dmtSXNts-dJm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:48:03.046329Z",
          "iopub.execute_input": "2024-12-05T21:48:03.046715Z",
          "iopub.status.idle": "2024-12-05T21:48:03.052346Z",
          "shell.execute_reply.started": "2024-12-05T21:48:03.046682Z",
          "shell.execute_reply": "2024-12-05T21:48:03.051505Z"
        },
        "id": "pGlc-YUY-dJn",
        "outputId": "d827f12d-6b00-4ca0-92d2-4b3abc5585e2"
      },
      "outputs": [
        {
          "execution_count": 134,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[{'translation_text': 'Genetic advice.'},\n {'translation_text': 'Graphical representation of the vestibular thermal test: the nystagmogram.'},\n {'translation_text': 'Dental education program. Escuelas normales de Santiago, Viña del mar and Curicó. 1965.'},\n {'translation_text': 'Evaluation of prostatic antigen specific post rectal touch: experience in 36 patients.'},\n {'translation_text': 'The use of antimuscarinics in male patients with symptoms of the lower urinary tract due to benign prostate hyperplasia and overactive bladder symptoms.'}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "[example['en'] for example in dataset[\"test\"]][:5]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:48:19.529155Z",
          "iopub.execute_input": "2024-12-05T21:48:19.529502Z",
          "iopub.status.idle": "2024-12-05T21:48:21.338333Z",
          "shell.execute_reply.started": "2024-12-05T21:48:19.52947Z",
          "shell.execute_reply": "2024-12-05T21:48:21.337445Z"
        },
        "id": "NB1c_eRS-dJn",
        "outputId": "8ff59963-a7af-4a57-d1c7-cfff1b1b8adb"
      },
      "outputs": [
        {
          "execution_count": 135,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Genetic counseling.',\n 'Graphic representation of the thermic vestibular test: the nystagmogram.',\n 'Dental educational program. Normal schools of Santiago, Viña del mar and Curicó. 1965.',\n 'Evaluation of prostatic specific antigen after a digital rectal examination: experience with 36 patients.',\n 'Use of antimuscarinics in patients with lower urinary tract symptoms for BPH and overactive bladder.']"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "[example['es'] for example in dataset[\"test\"]][:5]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T20:00:14.670975Z",
          "iopub.execute_input": "2024-12-05T20:00:14.67126Z",
          "iopub.status.idle": "2024-12-05T20:00:16.390267Z",
          "shell.execute_reply.started": "2024-12-05T20:00:14.671233Z",
          "shell.execute_reply": "2024-12-05T20:00:16.389364Z"
        },
        "id": "9XHREwyO-dJn",
        "outputId": "ed23a7de-208c-40ea-b2b6-7349042fdb9e"
      },
      "outputs": [
        {
          "execution_count": 118,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Consejo genético.',\n 'Representación gráfica de la prueba termica vestibular: el nistagmograma.',\n 'Programa educative odontológico. Escuelas normales de Santiago, Viña del mar y Curicó. 1965.',\n 'Evaluación del antigeno prostático especifico post tacto rectal: experiencia en 36 pacientes.',\n 'El uso de antimuscarínicos en pacientes varones con síntomas del tracto urinario inferior por hiperplasia benigna de próstata y sintomas de vejiga hiperactiva.']"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "result = metric.compute(predictions=[pred['translation_text'] for pred in predictions], references=[example['en'] for example in dataset[\"test\"]][:5])\n",
        "print(result)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:48:28.057653Z",
          "iopub.execute_input": "2024-12-05T21:48:28.05799Z",
          "iopub.status.idle": "2024-12-05T21:48:29.8022Z",
          "shell.execute_reply.started": "2024-12-05T21:48:28.057958Z",
          "shell.execute_reply": "2024-12-05T21:48:29.801285Z"
        },
        "id": "ovCx7qAs-dJn",
        "outputId": "1998f97e-8d8b-4c2d-a485-1f09697e5749"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{'score': 34.769941968239465, 'counts': [48, 28, 17, 9], 'totals': [69, 64, 59, 54], 'precisions': [69.56521739130434, 43.75, 28.8135593220339, 16.666666666666668], 'bp': 1.0, 'sys_len': 69, 'ref_len': 63}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:48:32.830246Z",
          "iopub.execute_input": "2024-12-05T21:48:32.831052Z",
          "iopub.status.idle": "2024-12-05T21:48:32.836109Z",
          "shell.execute_reply.started": "2024-12-05T21:48:32.831015Z",
          "shell.execute_reply": "2024-12-05T21:48:32.835187Z"
        },
        "id": "i9z3OlCI-dJn",
        "outputId": "bc786cd2-0989-4758-a350-e7f16aa8c257"
      },
      "outputs": [
        {
          "execution_count": 137,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'en', 'es', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 230248\n    })\n    test: Dataset({\n        features: ['id', 'en', 'es', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 28782\n    })\n    val: Dataset({\n        features: ['id', 'en', 'es', 'input_ids', 'attention_mask', 'labels'],\n        num_rows: 28781\n    })\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Actual OPUS-MT Training"
      ],
      "metadata": {
        "id": "oMcnGHc8-dJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset[\"val\"]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:49:09.336198Z",
          "iopub.execute_input": "2024-12-05T21:49:09.33657Z",
          "iopub.status.idle": "2024-12-05T21:49:09.34252Z",
          "shell.execute_reply.started": "2024-12-05T21:49:09.336537Z",
          "shell.execute_reply": "2024-12-05T21:49:09.341564Z"
        },
        "id": "w3KfFC24-dJn",
        "outputId": "46f86bf5-4d7d-47c3-cdc0-addd59c405a0"
      },
      "outputs": [
        {
          "execution_count": 139,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['id', 'en', 'es', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 28781\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"opus_mt_biomed_es_en_v1\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=0.02,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"val\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:51:00.618366Z",
          "iopub.execute_input": "2024-12-05T21:51:00.618749Z",
          "iopub.status.idle": "2024-12-05T21:51:34.034165Z",
          "shell.execute_reply.started": "2024-12-05T21:51:00.618716Z",
          "shell.execute_reply": "2024-12-05T21:51:34.033457Z"
        },
        "id": "UGAWwO8v-dJn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate(tokenized_dataset[\"val\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:52:40.071971Z",
          "iopub.execute_input": "2024-12-05T21:52:40.072306Z"
        },
        "id": "nQ7iGkNX-dJn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import TranslationEvaluator\n",
        "metric = TranslationEvaluator(task = \"translation\", default_metric_name = \"bleu\")\n",
        "evaluation_results = metric.compute(model_or_pipeline = model, tokenizer = tokenizer,\n",
        "                                    metric = \"bleu\", data = dataset[\"test\"],\n",
        "                                    device = \"cuda\",\n",
        "                                    input_column = \"es\", label_column = \"en\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "ThxSdrpr-dJn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPUS-MT Inference"
      ],
      "metadata": {
        "id": "vS5W3jRf-dJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/kaggle/working/opus_mt_biomed_es_en_v1/checkpoint-3598\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:10:42.443411Z",
          "iopub.execute_input": "2024-12-05T21:10:42.443735Z",
          "iopub.status.idle": "2024-12-05T21:10:43.534475Z",
          "shell.execute_reply.started": "2024-12-05T21:10:42.443709Z",
          "shell.execute_reply": "2024-12-05T21:10:43.533717Z"
        },
        "id": "D-mEURlP-dJn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"test\"][0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:10:44.13363Z",
          "iopub.execute_input": "2024-12-05T21:10:44.133956Z",
          "iopub.status.idle": "2024-12-05T21:10:44.140255Z",
          "shell.execute_reply.started": "2024-12-05T21:10:44.133926Z",
          "shell.execute_reply": "2024-12-05T21:10:44.139453Z"
        },
        "id": "8EoxlNIJ-dJn",
        "outputId": "293a93cf-7d09-4cef-9b26-a6b040b52b0a"
      },
      "outputs": [
        {
          "execution_count": 123,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'id': 3662268, 'en': 'Genetic counseling.', 'es': 'Consejo genético.'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation\", model=model_path, device=\"cuda\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:10:46.093043Z",
          "iopub.execute_input": "2024-12-05T21:10:46.09375Z",
          "iopub.status.idle": "2024-12-05T21:10:47.329757Z",
          "shell.execute_reply.started": "2024-12-05T21:10:46.09371Z",
          "shell.execute_reply": "2024-12-05T21:10:47.329028Z"
        },
        "id": "r1QLDvVk-dJn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = translator([example['es'] for example in dataset[\"test\"]][:5])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:10:51.009775Z",
          "iopub.execute_input": "2024-12-05T21:10:51.01008Z",
          "iopub.status.idle": "2024-12-05T21:10:53.651953Z",
          "shell.execute_reply.started": "2024-12-05T21:10:51.010052Z",
          "shell.execute_reply": "2024-12-05T21:10:53.650837Z"
        },
        "id": "hCmd9Iy3-dJn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:10:59.181269Z",
          "iopub.execute_input": "2024-12-05T21:10:59.181604Z",
          "iopub.status.idle": "2024-12-05T21:10:59.187955Z",
          "shell.execute_reply.started": "2024-12-05T21:10:59.18157Z",
          "shell.execute_reply": "2024-12-05T21:10:59.18683Z"
        },
        "id": "Fn310-QP-dJn",
        "outputId": "bbedf19e-aee5-4155-b983-8d6c77fd7974"
      },
      "outputs": [
        {
          "execution_count": 126,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[{'translation_text': 'Genetic counseling.'},\n {'translation_text': 'Graphic representation of vestibular thermal test: the nystagmogram.'},\n {'translation_text': 'Dental education program. Normal schools of Santiago, Viña del mar and Curicó. 1965.'},\n {'translation_text': 'Evaluation of the specific prostatic antigen after rectal touch: experience in 36 patients.'},\n {'translation_text': 'Use of antimuscarinics in male patients with symptoms of the lower urinary tract caused by benign prostatic hyperplasia and symptoms of overactive bladder.'}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = translator([example['es'] for example in dataset[\"test\"]])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T21:11:30.810327Z",
          "iopub.execute_input": "2024-12-05T21:11:30.810687Z",
          "iopub.status.idle": "2024-12-05T21:31:33.157794Z",
          "shell.execute_reply.started": "2024-12-05T21:11:30.810659Z",
          "shell.execute_reply": "2024-12-05T21:31:33.156154Z"
        },
        "id": "88wKJAZ7-dJn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "result = metric.compute(predictions=[pred['translation_text'] for pred in predictions], references=[example['en'] for example in dataset[\"test\"]][:5])\n",
        "print(result)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T19:02:20.507786Z",
          "iopub.execute_input": "2024-12-05T19:02:20.508141Z",
          "iopub.status.idle": "2024-12-05T19:02:23.979414Z",
          "shell.execute_reply.started": "2024-12-05T19:02:20.508106Z",
          "shell.execute_reply": "2024-12-05T19:02:23.978547Z"
        },
        "id": "vwDf7TEx-dJo",
        "outputId": "e7fa3bda-7c9b-4e94-d67c-d68bec7e68ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{'score': 54.82234750454774, 'counts': [36, 25, 16, 10], 'totals': [41, 36, 31, 26], 'precisions': [87.8048780487805, 69.44444444444444, 51.61290322580645, 38.46153846153846], 'bp': 0.9294421312368021, 'sys_len': 41, 'ref_len': 44}\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 (t5-small)"
      ],
      "metadata": {
        "id": "ejV6ZWA7-dJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "trusted": true,
        "id": "M09lJxrr-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/kaggle/input/wmt16-biomedical-mt-en-es/wmt16_biomedical_data_en_es.csv\"\n",
        "dataset = load_dataset(\"csv\", data_files=data_dir)"
      ],
      "metadata": {
        "trusted": true,
        "id": "CyUllCmk-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset[\"train\"].train_test_split(test_size=0.2)\n",
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "Yq_Iedfu-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "gmQXjjwp-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "source_lang = \"es\"\n",
        "target_lang = \"en\"\n",
        "prefix = \"translate Spanish to English: \"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = [prefix + example for example in examples[\"es\"]]\n",
        "    targets = [example for example in examples[\"en\"]]\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=256, truncation=True)\n",
        "    return model_inputs"
      ],
      "metadata": {
        "trusted": true,
        "id": "DTcgNe7Z-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "JEKswiNO-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Jn7iZ4FQ-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "LuTO1xi3-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels"
      ],
      "metadata": {
        "trusted": true,
        "id": "j4i9ZDbH-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ],
      "metadata": {
        "trusted": true,
        "id": "axM87hYs-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "D5F45r17-dJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-kw8Bww9-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"t5_small_biomed_es_en_v1\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "id": "npvWMR77-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "trusted": true,
        "id": "JCu1G4Fe-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "3DM5CYqy-dJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/kaggle/working/t5_small_biomed_es_en_v1/checkpoint-3598\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rIKy53Y_-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation\", model=model_path, device=\"cuda\")\n",
        "pred = translator([src, src])"
      ],
      "metadata": {
        "trusted": true,
        "id": "KYzs43d3-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = translator([example['es'] for example in dataset[\"test\"]][:5])"
      ],
      "metadata": {
        "trusted": true,
        "id": "Q_4wzuEI-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "result = metric.compute(predictions=[pred['translation_text'] for pred in predictions], references=[example['en'] for example in dataset[\"test\"]][:5])\n",
        "print(result)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZRcDvbup-dJo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r opus_mt_biomed_es_en_v1.zip /kaggle/working/opus_mt_biomed_es_en_v1/checkpoint-3598"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-05T19:31:14.799789Z",
          "iopub.execute_input": "2024-12-05T19:31:14.800097Z",
          "iopub.status.idle": "2024-12-05T19:32:01.502635Z",
          "shell.execute_reply.started": "2024-12-05T19:31:14.800069Z",
          "shell.execute_reply": "2024-12-05T19:32:01.501637Z"
        },
        "id": "VbgwO4wP-dJp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline: LSTM (using PyTorch)"
      ],
      "metadata": {
        "id": "aKFlrHue-dJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, es_texts, en_texts, max_length=50):\n",
        "        self.es_texts = es_texts\n",
        "        self.en_texts = en_texts\n",
        "\n",
        "        # Create vocabulary with reverse mapping\n",
        "        self.es_vocab = self.build_vocab(es_texts)\n",
        "        self.en_vocab = self.build_vocab(en_texts)\n",
        "\n",
        "        # Create reverse vocabulary for decoding\n",
        "        self.es_idx_to_char = {v: k for k, v in self.es_vocab.items()}\n",
        "        self.en_idx_to_char = {v: k for k, v in self.en_vocab.items()}\n",
        "\n",
        "        # Encode texts\n",
        "        self.es_encoded = [self.encode_text(text, self.es_vocab)[:max_length] for text in es_texts]\n",
        "        self.en_encoded = [self.encode_text(text, self.en_vocab)[:max_length] for text in en_texts]\n",
        "\n",
        "    def build_vocab(self, texts):\n",
        "        # Simple character-level vocabulary\n",
        "        chars = set(''.join(texts))\n",
        "        vocab = {char: i+2 for i, char in enumerate(chars)}\n",
        "        vocab['<PAD>'] = 0\n",
        "        vocab['<UNK>'] = 1\n",
        "        return vocab\n",
        "\n",
        "    def encode_text(self, text, vocab):\n",
        "        return torch.tensor([vocab.get(char, vocab['<UNK>']) for char in text])\n",
        "\n",
        "    def decode_text(self, encoded_text, idx_to_char):\n",
        "        return ''.join([idx_to_char.get(idx.item(), '') for idx in encoded_text])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.es_texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.es_encoded[idx], self.en_encoded[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Separate source and target sequences\n",
        "    es_sequences, en_sequences = zip(*batch)\n",
        "\n",
        "    # Pad sequences\n",
        "    es_padded = pad_sequence(es_sequences, batch_first=True, padding_value=0)\n",
        "    en_padded = pad_sequence(en_sequences, batch_first=True, padding_value=0)\n",
        "\n",
        "    return es_padded, en_padded\n",
        "\n",
        "class TranslationModel(nn.Module):\n",
        "    def __init__(self, input_vocab_size, output_vocab_size, hidden_size=64):\n",
        "        super().__init__()\n",
        "        self.input_vocab_size = input_vocab_size\n",
        "        self.output_vocab_size = output_vocab_size\n",
        "\n",
        "        # Embedding layers instead of one-hot encoding\n",
        "        self.es_embedding = nn.Embedding(input_vocab_size, hidden_size)\n",
        "        self.en_embedding = nn.Embedding(output_vocab_size, hidden_size)\n",
        "\n",
        "        self.encoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.output_layer = nn.Linear(hidden_size, output_vocab_size)\n",
        "\n",
        "    def forward(self, input_seq, target_seq):\n",
        "        # Embed input sequences\n",
        "        es_embedded = self.es_embedding(input_seq)\n",
        "        en_embedded = self.en_embedding(target_seq)\n",
        "\n",
        "        # Encode input sequence\n",
        "        encoder_outputs, (hidden, cell) = self.encoder(es_embedded)\n",
        "\n",
        "        # Decoder training\n",
        "        decoder_outputs, _ = self.decoder(en_embedded, (hidden, cell))\n",
        "        outputs = self.output_layer(decoder_outputs)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def translate(self, input_seq, max_length=50):\n",
        "        # Embed input sequence\n",
        "        input_embedded = self.es_embedding(input_seq)\n",
        "\n",
        "        # Encode input sequence\n",
        "        encoder_outputs, (hidden, cell) = self.encoder(input_embedded)\n",
        "\n",
        "        # Initialize decoder input\n",
        "        decoder_input = torch.zeros((input_seq.size(0), 1), dtype=torch.long, device=input_seq.device)\n",
        "\n",
        "        # Store decoded sequences\n",
        "        decoded_sequences = []\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            # Embed decoder input\n",
        "            decoder_embedded = self.en_embedding(decoder_input)\n",
        "\n",
        "            # Decode\n",
        "            decoder_output, (hidden, cell) = self.decoder(decoder_embedded, (hidden, cell))\n",
        "            output = self.output_layer(decoder_output)\n",
        "\n",
        "            # Get the most probable character\n",
        "            predicted_char_idx = output.argmax(dim=-1)\n",
        "            decoded_sequences.append(predicted_char_idx)\n",
        "\n",
        "            # Update decoder input\n",
        "            decoder_input = predicted_char_idx\n",
        "\n",
        "        return torch.cat(decoded_sequences, dim=1)\n",
        "\n",
        "from tqdm import tqdm\n",
        "def train_model(model, dataloader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        total_loss = 0\n",
        "        for es_batch, en_batch in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(es_batch, en_batch[:, :-1])\n",
        "\n",
        "            # Compute loss (shift targets by one for next-token prediction)\n",
        "            loss = criterion(outputs.reshape(-1, outputs.size(-1)), en_batch[:, 1:].reshape(-1))\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {total_loss/len(dataloader)}')\n",
        "\n",
        "# Main execution remains the same as in previous implementation\n",
        "# Load dataset\n",
        "df = pd.read_csv('/kaggle/input/wmt16-biomed-en-es/wmt16_biomedical_data_en_es.csv')\n",
        "\n",
        "# Split into train and test sets\n",
        "train_es, test_es, train_en, test_en = train_test_split(\n",
        "    df['es'], df['en'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:21:12.160368Z",
          "iopub.execute_input": "2024-12-06T03:21:12.160717Z",
          "iopub.status.idle": "2024-12-06T03:21:15.524597Z",
          "shell.execute_reply.started": "2024-12-06T03:21:12.160687Z",
          "shell.execute_reply": "2024-12-06T03:21:15.523562Z"
        },
        "id": "e-z7gjFB-dJp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training dataset and dataloader\n",
        "train_dataset = TranslationDataset(train_es.tolist(), train_en.tolist())\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = TranslationDataset(test_es.tolist(), test_en.tolist())\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:21:26.865938Z",
          "iopub.execute_input": "2024-12-06T03:21:26.866941Z",
          "iopub.status.idle": "2024-12-06T03:21:31.432056Z",
          "shell.execute_reply.started": "2024-12-06T03:21:26.86689Z",
          "shell.execute_reply": "2024-12-06T03:21:31.431043Z"
        },
        "id": "gov3rrAy-dJp"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = TranslationModel(\n",
        "    input_vocab_size=len(train_dataset.es_vocab),\n",
        "    output_vocab_size=len(train_dataset.en_vocab)\n",
        ")\n",
        "\n",
        "# Training setup\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:22:02.00815Z",
          "iopub.execute_input": "2024-12-06T03:22:02.008465Z",
          "iopub.status.idle": "2024-12-06T03:22:02.693946Z",
          "shell.execute_reply.started": "2024-12-06T03:22:02.008439Z",
          "shell.execute_reply": "2024-12-06T03:22:02.693229Z"
        },
        "id": "Lg99goJN-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "train_model(model, train_dataloader, criterion, optimizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:22:06.740317Z",
          "iopub.execute_input": "2024-12-06T03:22:06.740882Z",
          "iopub.status.idle": "2024-12-06T03:22:38.793742Z",
          "shell.execute_reply.started": "2024-12-06T03:22:06.740844Z",
          "shell.execute_reply": "2024-12-06T03:22:38.792803Z"
        },
        "id": "B9Kuz4sZ-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_dataset):\n",
        "    model.eval()\n",
        "    references = []\n",
        "    candidates = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(test_dataset)):\n",
        "            # Get a single input sequence\n",
        "            es_seq, en_seq = test_dataset[i]\n",
        "\n",
        "            # Translate the input sequence\n",
        "            translation = model.translate(es_seq.unsqueeze(0))\n",
        "\n",
        "            # Decode original and translated text\n",
        "            ref_text = test_dataset.decode_text(en_seq, test_dataset.en_idx_to_char)\n",
        "            trans_text = test_dataset.decode_text(translation.squeeze(0), test_dataset.en_idx_to_char)\n",
        "\n",
        "            # Prepare for BLEU score calculation\n",
        "            references.append([list(ref_text)])\n",
        "            candidates.append(list(trans_text))\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    bleu_score = corpus_bleu(references, candidates)\n",
        "\n",
        "    return bleu_score, references, candidates"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:32:05.617731Z",
          "iopub.execute_input": "2024-12-06T03:32:05.618433Z",
          "iopub.status.idle": "2024-12-06T03:32:05.624263Z",
          "shell.execute_reply.started": "2024-12-06T03:32:05.6184Z",
          "shell.execute_reply": "2024-12-06T03:32:05.623318Z"
        },
        "id": "4S-K_QRf-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "print(\"\\nEvaluating Model...\")\n",
        "bleu_score, references, candidates = evaluate_model(model, test_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:32:08.693002Z",
          "iopub.execute_input": "2024-12-06T03:32:08.693715Z",
          "iopub.status.idle": "2024-12-06T03:32:08.774959Z",
          "shell.execute_reply.started": "2024-12-06T03:32:08.693679Z",
          "shell.execute_reply": "2024-12-06T03:32:08.773733Z"
        },
        "id": "qDfY42hs-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Print evaluation results\n",
        "print(f\"\\nBLEU Score: {bleu_score}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "nvdXLI5q-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some example translations\n",
        "print(\"\\nExample Translations:\")\n",
        "for i in range(min(5, len(references))):\n",
        "    ref = ''.join(references[i][0])\n",
        "    cand = ''.join(candidates[i])\n",
        "    print(f\"Spanish Input:  {test_es.iloc[i]}\")\n",
        "    print(f\"Reference:      {ref}\")\n",
        "    print(f\"Candidate:      {cand}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "UBC0VHb3-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline: LSTM (using TensorFlow)"
      ],
      "metadata": {
        "id": "8OnfRi8S-dJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import nltk\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Configuration\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "MAX_SEQUENCE_LENGTH = 50\n",
        "EMBEDDING_DIM = 256\n",
        "LSTM_UNITS = 512\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:44:33.280208Z",
          "iopub.execute_input": "2024-12-06T03:44:33.281181Z",
          "iopub.status.idle": "2024-12-06T03:44:33.2873Z",
          "shell.execute_reply.started": "2024-12-06T03:44:33.281132Z",
          "shell.execute_reply": "2024-12-06T03:44:33.286333Z"
        },
        "id": "jCvEVRu2-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Load CSV\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Remove any rows with missing translations\n",
        "    df.dropna(subset=['es', 'en'], inplace=True)\n",
        "\n",
        "    # Preprocessing\n",
        "    df['es'] = df['es'].str.lower()\n",
        "    df['en'] = df['en'].str.lower()\n",
        "\n",
        "    return df['es'].tolist(), df['en'].tolist()\n",
        "\n",
        "# Tokenize and prepare sequences\n",
        "def prepare_sequences(spanish_texts, english_texts):\n",
        "    # Tokenize Spanish input\n",
        "    spanish_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token='<OOV>')\n",
        "    spanish_tokenizer.fit_on_texts(spanish_texts)\n",
        "    spanish_sequences = spanish_tokenizer.texts_to_sequences(spanish_texts)\n",
        "    spanish_padded = pad_sequences(spanish_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "    # Tokenize English output\n",
        "    english_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token='<OOV>')\n",
        "    english_tokenizer.fit_on_texts(english_texts)\n",
        "    english_sequences = english_tokenizer.texts_to_sequences(english_texts)\n",
        "    english_padded = pad_sequences(english_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "    return (spanish_padded, spanish_tokenizer,\n",
        "            english_padded, english_tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:44:33.28838Z",
          "iopub.execute_input": "2024-12-06T03:44:33.288657Z",
          "iopub.status.idle": "2024-12-06T03:44:33.300225Z",
          "shell.execute_reply.started": "2024-12-06T03:44:33.288631Z",
          "shell.execute_reply": "2024-12-06T03:44:33.299295Z"
        },
        "id": "Ll5AO_Po-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create seq2seq LSTM model\n",
        "def create_translation_model(input_vocab_size, output_vocab_size):\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "    encoder_embedding = Embedding(input_vocab_size, EMBEDDING_DIM)(encoder_inputs)\n",
        "    encoder = LSTM(LSTM_UNITS, return_state=True)\n",
        "    encoder_outputs, state_h, state_c = encoder(encoder_embedding)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "    decoder_embedding = Embedding(output_vocab_size, EMBEDDING_DIM)(decoder_inputs)\n",
        "    decoder_lstm = LSTM(LSTM_UNITS, return_sequences=True, return_state=True)\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "    # Output layer\n",
        "    decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Create model\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:44:33.301898Z",
          "iopub.execute_input": "2024-12-06T03:44:33.302751Z",
          "iopub.status.idle": "2024-12-06T03:44:33.313545Z",
          "shell.execute_reply.started": "2024-12-06T03:44:33.302722Z",
          "shell.execute_reply": "2024-12-06T03:44:33.312855Z"
        },
        "id": "brV9mM-F-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute BLEU score\n",
        "def compute_bleu_score(true_translations, predicted_translations):\n",
        "    # Tokenize references and hypotheses\n",
        "    references = [[nltk.word_tokenize(ref)] for ref in true_translations]\n",
        "    hypotheses = [nltk.word_tokenize(hyp) for hyp in predicted_translations]\n",
        "\n",
        "    # Compute BLEU score\n",
        "    bleu_score = corpus_bleu(references, hypotheses)\n",
        "    return bleu_score\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:44:33.314492Z",
          "iopub.execute_input": "2024-12-06T03:44:33.314812Z",
          "iopub.status.idle": "2024-12-06T03:44:33.326977Z",
          "shell.execute_reply.started": "2024-12-06T03:44:33.314787Z",
          "shell.execute_reply": "2024-12-06T03:44:33.326159Z"
        },
        "id": "R32nvHxg-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training and evaluation function\n",
        "def train_translation_model(data_path):\n",
        "    # Load data\n",
        "    spanish_texts, english_texts = load_and_preprocess_data(data_path)\n",
        "\n",
        "    # Split data\n",
        "    train_es, test_es, train_en, test_en = train_test_split(\n",
        "        spanish_texts, english_texts, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Prepare sequences\n",
        "    X_train, spanish_tokenizer, y_train, english_tokenizer = prepare_sequences(train_es, train_en)\n",
        "    X_test, _, y_test, _ = prepare_sequences(test_es, test_en)\n",
        "\n",
        "    # Create model\n",
        "    model = create_translation_model(\n",
        "        len(spanish_tokenizer.word_index) + 1,\n",
        "        len(english_tokenizer.word_index) + 1\n",
        "    )\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "    # Prepare target data for sparse categorical crossentropy\n",
        "    y_train_sparse = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
        "\n",
        "    # Train model\n",
        "    model.fit(\n",
        "        [X_train, y_train],\n",
        "        y_train_sparse,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        validation_split=0.2\n",
        "    )\n",
        "\n",
        "    # Predict translations\n",
        "    predictions = model.predict([X_test, y_test])\n",
        "\n",
        "    # Convert predictions to text (simplified)\n",
        "    predicted_translations = []\n",
        "    for pred in predictions:\n",
        "        # Get the most likely token for each position\n",
        "        predicted_tokens = np.argmax(pred, axis=-1)\n",
        "\n",
        "        # Convert back to text\n",
        "        predicted_text = ' '.join([\n",
        "            list(english_tokenizer.word_index.keys())[list(english_tokenizer.word_index.values()).index(token)]\n",
        "            for token in predicted_tokens if token != 0\n",
        "        ])\n",
        "        predicted_translations.append(predicted_text)\n",
        "\n",
        "    # Compute BLEU score\n",
        "    bleu_score = compute_bleu_score(test_en, predicted_translations)\n",
        "\n",
        "    print(f\"BLEU Score: {bleu_score}\")\n",
        "\n",
        "    return model, spanish_tokenizer, english_tokenizer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:44:33.327883Z",
          "iopub.execute_input": "2024-12-06T03:44:33.328213Z",
          "iopub.status.idle": "2024-12-06T03:44:33.337726Z",
          "shell.execute_reply.started": "2024-12-06T03:44:33.328174Z",
          "shell.execute_reply": "2024-12-06T03:44:33.336998Z"
        },
        "id": "sdAxp1M8-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Example translation function\n",
        "def translate(spanish_text):\n",
        "    # Tokenize and pad input\n",
        "    input_sequence = es_tokenizer.texts_to_sequences([spanish_text])\n",
        "    input_padded = pad_sequences(input_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "    # Predict translation\n",
        "    prediction = model.predict([input_padded, input_padded])\n",
        "    predicted_tokens = np.argmax(prediction, axis=-1)\n",
        "\n",
        "    # Convert back to text\n",
        "    translated_text = ' '.join([\n",
        "        list(en_tokenizer.word_index.keys())[list(en_tokenizer.word_index.values()).index(token)]\n",
        "        for token in predicted_tokens[0] if token != 0\n",
        "    ])\n",
        "\n",
        "    return translated_text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:44:33.338618Z",
          "iopub.execute_input": "2024-12-06T03:44:33.33929Z",
          "iopub.status.idle": "2024-12-06T03:44:33.351143Z",
          "shell.execute_reply.started": "2024-12-06T03:44:33.339243Z",
          "shell.execute_reply": "2024-12-06T03:44:33.350255Z"
        },
        "id": "frVVJ3QD-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Main training and evaluation function\n",
        "data_path = \"/kaggle/input/wmt16-biomed-en-es/wmt16_biomedical_data_en_es.csv\"\n",
        "# Load data\n",
        "spanish_texts, english_texts = load_and_preprocess_data(data_path)\n",
        "\n",
        "# Split data\n",
        "train_es, test_es, train_en, test_en = train_test_split(\n",
        "    spanish_texts, english_texts, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Prepare sequences\n",
        "X_train, spanish_tokenizer, y_train, english_tokenizer = prepare_sequences(train_es, train_en)\n",
        "X_test, _, y_test, _ = prepare_sequences(test_es, test_en)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:44:33.779935Z",
          "iopub.execute_input": "2024-12-06T03:44:33.780237Z",
          "iopub.status.idle": "2024-12-06T03:44:53.254554Z",
          "shell.execute_reply.started": "2024-12-06T03:44:33.780209Z",
          "shell.execute_reply": "2024-12-06T03:44:53.253422Z"
        },
        "id": "ziFg9u2C-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "model = create_translation_model(\n",
        "    len(spanish_tokenizer.word_index) + 1,\n",
        "    len(english_tokenizer.word_index) + 1\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:44:53.256663Z",
          "iopub.execute_input": "2024-12-06T03:44:53.257485Z",
          "iopub.status.idle": "2024-12-06T03:44:54.237842Z",
          "shell.execute_reply.started": "2024-12-06T03:44:53.25744Z",
          "shell.execute_reply": "2024-12-06T03:44:54.236863Z"
        },
        "id": "1QasVF8F-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:44:54.238956Z",
          "iopub.execute_input": "2024-12-06T03:44:54.239246Z",
          "iopub.status.idle": "2024-12-06T03:44:54.251615Z",
          "shell.execute_reply.started": "2024-12-06T03:44:54.239218Z",
          "shell.execute_reply": "2024-12-06T03:44:54.250789Z"
        },
        "id": "iaScJTbg-dJq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare target data for sparse categorical crossentropy\n",
        "y_train_sparse = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
        "\n",
        "# Train model\n",
        "model.fit(\n",
        "    [X_train, y_train],\n",
        "    y_train_sparse,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-06T03:44:54.253125Z",
          "iopub.execute_input": "2024-12-06T03:44:54.253395Z"
        },
        "id": "Tegd8_ds-dJs"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict translations\n",
        "predictions = model.predict([X_test, y_test])\n",
        "\n",
        "# Convert predictions to text (simplified)\n",
        "predicted_translations = []\n",
        "for pred in predictions:\n",
        "    # Get the most likely token for each position\n",
        "    predicted_tokens = np.argmax(pred, axis=-1)\n",
        "\n",
        "    # Convert back to text\n",
        "    predicted_text = ' '.join([\n",
        "        list(english_tokenizer.word_index.keys())[list(english_tokenizer.word_index.values()).index(token)]\n",
        "        for token in predicted_tokens if token != 0\n",
        "    ])\n",
        "    predicted_translations.append(predicted_text)\n",
        "\n",
        "# Compute BLEU score\n",
        "bleu_score = compute_bleu_score(test_en, predicted_translations)\n",
        "\n",
        "print(f\"BLEU Score: {bleu_score}\")\n",
        "\n",
        "return model, spanish_tokenizer, english_tokenizer"
      ],
      "metadata": {
        "trusted": true,
        "id": "o1vCoUsw-dJs"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}